{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\".\")\n",
    "\n",
    "import model as modellib\n",
    "from config import Config\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Number of images used: 1500\n",
      "Class Count: 2\n",
      "  0. BG                                                \n",
      "  1. Litter                                            \n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import dataset\n",
    "\n",
    "# Load class map - these tables map the original TACO classes to your desired class system\n",
    "# and allow you to discard classes that you don't want to include.\n",
    "class_map = {}\n",
    "with open(\"./taco_config/map_1.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    class_map = {row[0]:row[1] for row in reader}\n",
    "\n",
    "# Load full dataset or a subset\n",
    "TACO_DIR = \"../../../data/tacodataset/\"\n",
    "round = None # Split number: If None, loads full dataset else if int > 0 selects split no \n",
    "subset = \"train\" # Used only when round !=None, Options: ('train','val','test') to select respective subset\n",
    "dataset = dataset.Taco()\n",
    "taco = dataset.load_taco(TACO_DIR, round, subset, class_map=class_map, return_taco=True)\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Class Count: {}\".format(dataset.num_classes))\n",
    "for i, info in enumerate(dataset.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BG: 0\n",
      "Litter: 4784\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Count annotations\n",
    "cat_histogram = np.zeros(dataset.num_classes,dtype=int)\n",
    "class_names = []\n",
    "for i, info in enumerate(dataset.class_info):\n",
    "    ann_per_cat = taco.getAnnIds(catIds=i, iscrowd=None)\n",
    "    cat_histogram[i] = len(ann_per_cat)\n",
    "    class_names.append(info['name'])\n",
    "\n",
    "for i in range(2):\n",
    "    print(f\"{class_names[i]}: {cat_histogram[i]}\")\n",
    "\n",
    "\n",
    "# As we are doing object segmentation and not image classification, we can work with only positive examples. \n",
    "# The background of the image will be serving as the negative example. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TacoTestConfig(Config):\n",
    "    NAME = \"taco\"\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.3\n",
    "    NUM_CLASSES = dataset.num_classes\n",
    "#     IMAGE_MAX_DIM = 1024\n",
    "#     IMAGE_MIN_DIM = 1024\n",
    "#     IMAGE_RESIZE_MODE = \"square\"\n",
    "config = TacoTestConfig()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image original shape: (3264, 2448, 3)\n",
      "Bbox original shape: 882 431 1998 1593\n",
      "Downscaling image by 0.3899790465726482\n",
      "Scale interval: 0.3137254901960784 0.8812392426850258\n",
      "Image resized shape: (1273, 1273, 3)\n",
      "(0, 0, 1024, 898)\n",
      "Image original shape: (3264, 2448, 3)\n",
      "Bbox original shape: 1398 1175 2117 1926\n",
      "(0, 0, -199, -36)\n"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "from random import randint\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "\n",
    "seed(1)\n",
    "\n",
    "# Load random image\n",
    "image_id = np.random.choice(len(dataset.image_ids))\n",
    "image_ori = dataset.load_image(image_id)\n",
    "masks_ori, _ = dataset.load_mask(image_id)\n",
    "\n",
    "image_dtype = image_ori.dtype\n",
    "nr_annotations = np.shape(masks_ori)[-1]\n",
    "\n",
    "bboxes = utils.extract_bboxes(masks_ori)\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "fig, ax = plt.subplots(nr_annotations+1, 1, figsize=(10,10*(nr_annotations+1)))\n",
    "ax[0].imshow(image_ori)\n",
    "\n",
    "i=0\n",
    "for bbox_id in range(len(bboxes)):\n",
    "    \n",
    "    image = image_ori\n",
    "    masks = masks_ori\n",
    "    \n",
    "    bboxes_cpy = bboxes\n",
    "    y1, x1, y2, x2 = bboxes_cpy[bbox_id]\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    bbox_width = x2-x1\n",
    "    bbox_height = y2-y1\n",
    "    \n",
    "    img_max_dim = max(h,w)\n",
    "    bbox_max_dim = max(bbox_width,bbox_height)\n",
    "    \n",
    "    print('Image original shape:',image.shape)\n",
    "    print('Bbox original shape:',y1, x1, y2, x2)\n",
    "    \n",
    "    bbox_max_dim_threshold_4_scaling = config.IMAGE_MAX_DIM*0.8\n",
    "    \n",
    "    # If bbox is big enough or too big, downsize full image\n",
    "    if bbox_max_dim > bbox_max_dim_threshold_4_scaling:\n",
    "        \n",
    "        # Rescale\n",
    "        downscale_at_least = min(1.,config.IMAGE_MAX_DIM/bbox_max_dim)\n",
    "        downscale_min = config.IMAGE_MAX_DIM/img_max_dim\n",
    "        \n",
    "        scale = random.random()*(downscale_at_least-downscale_min)+downscale_min\n",
    "        \n",
    "        print('Downscaling image by',scale)\n",
    "        print(\"Scale interval:\", downscale_min, downscale_at_least)\n",
    "        \n",
    "        # Actually scale Image   \n",
    "        image = skimage.transform.resize(image, (np.round(h * scale), np.round(w * scale)),order=1,\n",
    "                                         mode=\"constant\", preserve_range=True)\n",
    "    \n",
    "        h, w = image.shape[:2]\n",
    "        img_max_dim = max(h,w)\n",
    "    \n",
    "        # Padding\n",
    "        top_pad = (img_max_dim - h) // 2\n",
    "        bottom_pad = img_max_dim - h - top_pad\n",
    "        left_pad = (img_max_dim - w) // 2\n",
    "        right_pad = img_max_dim - w - left_pad\n",
    "        padding = [(top_pad, bottom_pad), (left_pad, right_pad), (0, 0)]\n",
    "        image = np.pad(image, padding, mode='constant', constant_values=0).astype(image_dtype)\n",
    "        window = (top_pad, left_pad, h + top_pad, w + left_pad)\n",
    "        \n",
    "        # Adjust mask and other vars\n",
    "        masks = utils.resize_mask(masks, scale, padding)\n",
    "        bboxes_cpy = utils.extract_bboxes(masks)\n",
    "        y1, x1, y2, x2 = bboxes_cpy[bbox_id]\n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        print('Image resized shape:',image.shape)\n",
    "    \n",
    "    # Select crop around target annotation\n",
    "    x0_min = max(x2-config.IMAGE_MAX_DIM,0) \n",
    "    x0_max = min(x1,w-config.IMAGE_MAX_DIM)\n",
    "    x0 = randint(x0_min, x0_max)\n",
    "    y0_min = max(y2-config.IMAGE_MAX_DIM,0) \n",
    "    y0_max = min(y1,h-config.IMAGE_MAX_DIM)\n",
    "    y0 = randint(y0_min, y0_max)\n",
    "    \n",
    "    if padding:\n",
    "        max_dim = config.IMAGE_MAX_DIM\n",
    "        window = (max(top_pad,y0)-y0, max(left_pad,x0)-x0, min(window[2],y0+max_dim)-y0, min(window[3],x0+max_dim)-x0)\n",
    "        print(window)\n",
    "    \n",
    "    # Crop\n",
    "    crop = (y0, x0, config.IMAGE_MAX_DIM, config.IMAGE_MAX_DIM)\n",
    "    image = image[y0:y0 + config.IMAGE_MAX_DIM, x0:x0 + config.IMAGE_MAX_DIM]\n",
    "    masks = masks[y0:y0 + config.IMAGE_MAX_DIM, x0:x0 + config.IMAGE_MAX_DIM]\n",
    "    ax[i+1].imshow(image)\n",
    "    ax[i+1].axis('off')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This may take some time, as we are working with the original image size...\n"
     ]
    }
   ],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import imageio\n",
    "\n",
    "#ia.seed(1)\n",
    "nr_augmentations = 10\n",
    "\n",
    "# Load random image\n",
    "# image_id = np.random.choice(len(dataset.image_ids))\n",
    "# image = dataset.load_image(image_id)\n",
    "# masks, _ = dataset.load_mask(image_id)\n",
    "\n",
    "# Define our augmentation pipeline.\n",
    "seq = iaa.Sequential([\n",
    "        iaa.AdditiveGaussianNoise(scale=0.01 * 255, name=\"AWGN\"),\n",
    "        iaa.GaussianBlur(sigma=(0.0, 3.0), name=\"Blur\"),\n",
    "        # iaa.Dropout([0.0, 0.05], name='Dropout'), # drop 0-5% of all pixels\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Add((-20, 20),name=\"Add\"),\n",
    "        iaa.Multiply((0.8, 1.2), name=\"Multiply\"),\n",
    "#       iaa.Affine(scale=(0.8, 1.1)),\n",
    "#       iaa.Affine(translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}),\n",
    "        iaa.Affine(rotate=(-45, 45)),  # rotate by -45 to 45 degrees\n",
    "    ], random_order=True)\n",
    "\n",
    "# Change activated augmentors for masks\n",
    "def activator_masks(images, augmenter, parents, default):\n",
    "    if augmenter.name in [\"Blur\", \"AWGN\", \"Add\",\"Multiply\"]:\n",
    "        return False\n",
    "    else:\n",
    "        # default value for all other augmenters\n",
    "        return default\n",
    "    \n",
    "hooks_masks = ia.HooksImages(activator=activator_masks)\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "fig, aux = plt.subplots(ncols=2, nrows=nr_augmentations+1, figsize=(15,60))\n",
    "\n",
    "aux[0,0].imshow(image)\n",
    "aux[0,0].axis('off')\n",
    "aux[0,1].imshow(masks.sum(axis=2)) # form an unique segmask from multiple masks\n",
    "aux[0,1].axis('off')\n",
    "\n",
    "print('This may take some time, as we are working with the original image size...')\n",
    "\n",
    "# Augment images and masks\n",
    "for i in range(nr_augmentations):\n",
    "    seq_det = seq.to_deterministic()\n",
    "    image_augmented = seq_det.augment_image(image)\n",
    "    mask_augmented = seq_det.augment_image(masks.astype(np.uint8), hooks=hooks_masks)\n",
    "    seg_mask = mask_augmented.sum(axis=2)\n",
    "\n",
    "    aux[i+1,0].imshow(image_augmented)\n",
    "    aux[i+1,0].axis('off')\n",
    "    aux[i+1,1].imshow(seg_mask)\n",
    "    aux[i+1,1].axis('off')\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.2, hspace=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('BP-TACO')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00b4a173268c59f198d8bf6bd4f6f4d0ef318196cd1074ef1de27c4bc852830b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
